@article{CYHI,
  author       = {Stefanos Koffas and
                  Jing Xu and
                  Mauro Conti and
                  Stjepan Picek},
  title        = {Can You Hear It? Backdoor Attacks via Ultrasonic Triggers},
  journal      = {CoRR},
  volume       = {abs/2107.14569},
  year         = {2021},
  url          = {https://arxiv.org/abs/2107.14569},
  eprinttype    = {arXiv},
  eprint       = {2107.14569},
  timestamp    = {Tue, 03 Aug 2021 14:53:34 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2107-14569.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ASRHistory,
title = {Invited paper: Automatic speech recognition: History, methods and challenges},
journal = {Pattern Recognition},
volume = {41},
number = {10},
pages = {2965-2979},
year = {2008},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2008.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0031320308001799},
author = {Douglas O’Shaughnessy},
keywords = {Automatic speech recognition, Hidden Markov models, Adaptation, Compensation, Pattern recognition, Spectral representation},
abstract = {The field of automatic speech recognition (ASR) is discussed from the viewpoint of pattern recognition (PR). This tutorial examines the problem area, its methods, successes and failures, focusing on the nature of the speech signal and techniques to accomplish useful data reduction. Comparison is made with other areas of PR. Suggestions are given for areas of future progress.}
}


@inproceedings{BACKDOORMEMS,
author = {Roy, Nirupam and Hassanieh, Haitham and Roy Choudhury, Romit},
title = {BackDoor: Making Microphones Hear Inaudible Sounds},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081366},
doi = {10.1145/3081333.3081366},
abstract = {Consider sounds, say at 40kHz, that are completely outside the human's audible range (20kHz), as well as a microphone's recordable range (24kHz). We show that these high frequency sounds can be designed to become recordable by unmodified microphones, while remaining inaudible to humans. The core idea lies in exploiting non-linearities in microphone hardware. Briefly, we design the sound and play it on a speaker such that, after passing through the microphone's non-linear diaphragm and power-amplifier, the signal creates a "shadow" in the audible frequency range. The shadow can be regulated to carry data bits, thereby enabling an acoustic (but inaudible) communication channel to today's microphones. Other applications include jamming spy microphones in the environment, live watermarking of music in a concert, and even acoustic denial-of-service (DoS) attacks. This paper presents BackDoor, a system that develops the technical building blocks for harnessing this opportunity. Reported results achieve upwards of 4kbps for proximate data communication, as well as room-level privacy protection against electronic eavesdropping.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {2–14},
numpages = {13},
keywords = {communication, inaudible sound, smartphone, security, nonlinear acoustics, speech privacy, privacy, ultrasound, voice authentication, acoustic jamming, acoustics},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@article{StripVita,
  author       = {Yansong Gao and
                  Yeonjae Kim and
                  Bao Gia Doan and
                  Zhi Zhang and
                  Gongxuan Zhang and
                  Surya Nepal and
                  Damith Chinthana Ranasinghe and
                  Hyoungshick Kim},
  title        = {Design and Evaluation of a Multi-Domain Trojan Detection Method on
                  Deep Neural Networks},
  journal      = {CoRR},
  volume       = {abs/1911.10312},
  year         = {2019},
  url          = {http://arxiv.org/abs/1911.10312},
  eprinttype    = {arXiv},
  eprint       = {1911.10312},
  timestamp    = {Thu, 13 Aug 2020 09:46:05 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1911-10312.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@article{Strip,
  author       = {Yansong Gao and
                  Chang Xu and
                  Derui Wang and
                  Shiping Chen and
                  Damith Chinthana Ranasinghe and
                  Surya Nepal},
  title        = {{STRIP:} {A} Defence Against Trojan Attacks on Deep Neural Networks},
  journal      = {CoRR},
  volume       = {abs/1902.06531},
  year         = {2019},
  url          = {http://arxiv.org/abs/1902.06531},
  eprinttype    = {arXiv},
  eprint       = {1902.06531},
  timestamp    = {Mon, 18 Nov 2019 15:00:07 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1902-06531.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@article{dave2013feature,
  title={Feature extraction methods LPC, PLP and MFCC in speech recognition},
  author={Dave, Namrata},
  journal={International journal for advance research in engineering and technology},
  volume={1},
  number={6},
  pages={1--4},
  year={2013}
}


@article{SpokenLanguageProcessing,
author = {Huang, Xuedong and Acero, Alex and Hon, Hsiao-Wuen},
year = {2001},
month = {01},
pages = {},
title = {Spoken Language Processing: A Guide to Theory, Algorithm, and System Development}
}

@book{rabiner1978digital,
  title={Digital Processing of Speech Signals},
  author={Rabiner, L.R. and Schafer, R.W.},
  isbn={9780132136037},
  lccn={78008555},
  series={Prentice-Hall signal processing series},
  url={https://books.google.nl/books?id=YVtTAAAAMAAJ},
  year={1978},
  publisher={Prentice-Hall}
}

@article{Speech_commands,
  author    = {Pete Warden},
  title     = {Speech Commands: {A} Dataset for Limited-Vocabulary Speech Recognition},
  journal   = {CoRR},
  volume    = {abs/1804.03209},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.03209},
  eprinttype = {arXiv},
  eprint    = {1804.03209},
  timestamp = {Mon, 13 Aug 2018 16:48:32 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1804-03209.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{RASPBERRY,
  title = {{Raspberry Pi 3 Model B}},
  howpublished = {\url{https://www.raspberrypi.com/products/raspberry-pi-3-model-b/}},
  note = {Accessed: 2023-02-27}
}

@misc{HIFIBERRY,
  title = {{HiFiBerry DAC+ ADC}},
  howpublished = {\url{https://www.hifiberry.com/shop/boards/hifiberry-dac-adc}},
  note = {Accessed: 2023-02-27}
}

@misc{REDMI,
  title = {{Redmi Note 11 Pro 5G}},
  howpublished = {\url{https://www.mi.com/nl/redmi-note-11-pro-5g/}},
  note = {Accessed: 2023-02-27}
}

@misc{GH,
  title = {{Github | Bachelor Scriptie}},
  howpublished = {\url{https://github.com/Gulianrdgd/Bachelor-scriptie}},
  note = {Accessed: 2023-04-25}
}

@misc{CommonVoice,
  title = {{Common voice Mozilla}},
  howpublished = {\url{https://commonvoice.mozilla.org/en}},
  note = {Accessed: 2023-04-25}
}

@INPROCEEDINGS{7178964,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Librispeech: An ASR corpus based on public domain audio books}, 
  year={2015},
  volume={},
  number={},
  pages={5206-5210},
  doi={10.1109/ICASSP.2015.7178964}}


@misc{TenserflowExample,
  title = {{Tenserflow speech recognition example}},
  howpublished = {\url{https://www.tensorflow.org/lite/models/modify/model_maker/speech_recognition}},
  note = {Accessed: 2023-04-25}
}

@misc{Jlibrosa,
  title = {{jlibrosa github}},
  howpublished = {\url{https://github.com/Subtitle-Synchronizer/jlibrosa}},
  note = {Accessed: 2023-05-16}
}

@misc{Librosa,
  title = {{Librosa}},
  howpublished = {\url{https://librosa.org/doc/latest/index.html}},
  note = {Accessed: 2023-05-16}
}

@misc{AudioSpectrum,
  title = {{Apple app store - Audio Spectrum Analyzer Pro}},
  howpublished = {\url{https://apps.apple.com/us/app/audio-spectrum-analyzer-pro/id1152352806}},
    note = {Accessed: 2023-05-17}
}

@misc{Spectroid,
  title = {{Google play store - Spectroid}},
  howpublished = {\url{https://play.google.com/store/apps/details?id=org.intoorbit.spectrum}},
  note = {Accessed: 2023-05-17}
}

@misc{AndroidMediaRecorder,
  title = {{MediaRecorder | Android developer}},
  howpublished = {\url{https://developer.android.com/reference/android/media/MediaRecorder#setAudioSamplingRate(int)}},
  note = {Accessed: 2023-05-21}
}

@article{Zeng_2019,
doi = {10.1088/1742-6596/1345/5/052053},
url = {https://dx.doi.org/10.1088/1742-6596/1345/5/052053},
year = {2019},
month = {nov},
publisher = {IOP Publishing},
volume = {1345},
number = {5},
pages = {052053},
author = {Jinhua Zeng and Qiuxiu Lian and Shaopei Shi},
title = {Forensic originality identification of iPhone’s voice memos},
journal = {Journal of Physics: Conference Series},
abstract = {In this paper, we focus on the meta-data analysis methods and digital forensics techniques to solve the problem of forensic originality identification of audio recordings recorded by the Voice Memos App in the iPhone. The Voice Memos App is the built-in application for voice recording and editing in the iPhone. We first introduce the features of the Voice Memos App. Then, the experimental study is carried out to collect and analyze the original and the non-original audio recordings from different iPhones and iOS versions. The file structure pattern, time related file attribute information pattern, application database data pattern of the original audio recordings are analyzed and concluded in this paper, which can be valuable for forensic identification of original audio recordings.}
}



@INPROCEEDINGS{7180939,
  author={Wang, Zhe and Zou, Quanbo and Song, Qinglin and Tao, Jifang},
  booktitle={2015 Transducers - 2015 18th International Conference on Solid-State Sensors, Actuators and Microsystems (TRANSDUCERS)}, 
  title={The era of silicon MEMS microphone and look beyond}, 
  year={2015},
  volume={},
  number={},
  pages={375-378},
  doi={10.1109/TRANSDUCERS.2015.7180939}}

@article{por2019nyquist,
  title={Nyquist--Shannon sampling theorem},
  author={Por, Emiel and van Kooten, Maaike and Sarkovic, Vanja},
  journal={Leiden University},
  volume={1},
  number={1},
  year={2019}
}

@INPROCEEDINGS{1692543,
  author={Wei Han and Cheong-Fat Chan and Chiu-Sing Choy and Kong-Pang Pun},
  booktitle={2006 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={An efficient MFCC extraction method in speech recognition}, 
  year={2006},
  volume={},
  number={},
  pages={4 pp.-},
  doi={10.1109/ISCAS.2006.1692543}}


@inproceedings{POSTER,
author = {Song, Liwei and Mittal, Prateek},
title = {POSTER: Inaudible Voice Commands},
year = {2017},
isbn = {9781450349468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3133956.3138836},
doi = {10.1145/3133956.3138836},
abstract = {Voice assistants like Siri enable us to control IoT devices conveniently with voice commands, however, they also provide new attack opportunities for adversaries. Previous papers attack voice assistants with obfuscated voice commands by leveraging the gap between speech recognition system and human voice perception. The limitation is that these obfuscated commands are audible and thus conspicuous to device owners. In this poster, we propose a novel mechanism to directly attack the microphone used for sensing voice data with inaudible voice commands. We show that the adversary can exploit the microphone's non-linearity and play well-designed inaudible ultrasounds to cause the microphone to record normal voice commands, and thus control the victim device inconspicuously. We demonstrate via end-to-end real-world experiments that our inaudible voice commands can attack an Android phone and an Amazon Echo device with high success rates at a range of 2-3 meters.},
booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
pages = {2583–2585},
numpages = {3},
keywords = {inaudible ultrasound injection, microphone, intermodulation distortion, non-linearity},
location = {Dallas, Texas, USA},
series = {CCS '17}
}

@article{DOLPHIN,
  author       = {Guoming Zhang and
                  Chen Yan and
                  Xiaoyu Ji and
                  Taimin Zhang and
                  Tianchen Zhang and
                  Wenyuan Xu},
  title        = {DolphinAtack: Inaudible Voice Commands},
  journal      = {CoRR},
  volume       = {abs/1708.09537},
  year         = {2017},
  url          = {http://arxiv.org/abs/1708.09537},
  eprinttype    = {arXiv},
  eprint       = {1708.09537},
  timestamp    = {Sun, 28 May 2023 00:01:48 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1708-09537.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{JAMMER,
  author       = {Yuxin Chen and
                  Huiying Li and
                  Steven Nagels and
                  Zhijing Li and
                  Pedro Lopes and
                  Ben Y. Zhao and
                  Haitao Zheng},
  title        = {Understanding the Effectiveness of Ultrasonic Microphone Jammer},
  journal      = {CoRR},
  volume       = {abs/1904.08490},
  year         = {2019},
  url          = {http://arxiv.org/abs/1904.08490},
  eprinttype    = {arXiv},
  eprint       = {1904.08490},
  timestamp    = {Wed, 26 Apr 2023 08:16:48 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1904-08490.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@ARTICLE{BADNETS,
  author={Gu, Tianyu and Liu, Kang and Dolan-Gavitt, Brendan and Garg, Siddharth},
  journal={IEEE Access}, 
  title={BadNets: Evaluating Backdooring Attacks on Deep Neural Networks}, 
  year={2019},
  volume={7},
  number={},
  pages={47230-47244},
  doi={10.1109/ACCESS.2019.2909068}}


@InProceedings{BACKDOORCOMPARE,
author="Xin, Jinwen
and Lyu, Xixiang
and Ma, Jing",
editor="Xu, Yuan
and Yan, Hongyang
and Teng, Huang
and Cai, Jun
and Li, Jin",
title="Natural Backdoor Attacks on Speech Recognition Models",
booktitle="Machine Learning for Cyber Security",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="597--610",
abstract="With the rapid development of deep learning, its vulnerability has gradually emerged in recent years. This work focuses on backdoor attacks on speech recognition systems. We adopt sounds that are ordinary in nature or in our daily life as triggers for natural backdoor attacks. We conduct experiments on two datasets and three models to validate the performance of natural backdoor attacks and explore the effects of poisoning rate, trigger duration and blend ratio on the performance of natural backdoor attacks. Our results show that natural backdoor attacks have a high attack success rate without compromising model performance on benign samples, even with short or low-amplitude triggers. It requires only 5{\%} of poisoned samples to achieve a near 100{\%} attack success rate. In addition, the backdoor will be automatically activated by the corresponding sound in nature, which is not easy to be detected and will bring severer harm.",
isbn="978-3-031-20096-0"
}

@ARTICLE{OVERVIEWBACKDOOR,

  author={Guo, Wei and Tondi, Benedetta and Barni, Mauro},

  journal={IEEE Open Journal of Signal Processing}, 

  title={An Overview of Backdoor Attacks Against Deep Neural Networks and Possible Defences}, 

  year={2022},

  volume={3},

  number={},

  pages={261-287},

  doi={10.1109/OJSP.2022.3190213}}


@inproceedings{LATENTBACKDOORS,
author = {Yao, Yuanshun and Li, Huiying and Zheng, Haitao and Zhao, Ben Y.},
title = {Latent Backdoor Attacks on Deep Neural Networks},
year = {2019},
isbn = {9781450367479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319535.3354209},
doi = {10.1145/3319535.3354209},
abstract = {Recent work proposed the concept of backdoor attacks on deep neural networks (DNNs), where misclassification rules are hidden inside normal models, only to be triggered by very specific inputs. However, these "traditional" backdoors assume a context where users train their own models from scratch, which rarely occurs in practice. Instead, users typically customize "Teacher" models already pretrained by providers like Google, through a process called transfer learning. This customization process introduces significant changes to models and disrupts hidden backdoors, greatly reducing the actual impact of backdoors in practice. In this paper, we describe latent backdoors, a more powerful and stealthy variant of backdoor attacks that functions under transfer learning. Latent backdoors are incomplete backdoors embedded into a "Teacher" model, and automatically inherited by multiple "Student" models through transfer learning. If any Student models include the label targeted by the backdoor, then its customization process completes the backdoor and makes it active. We show that latent backdoors can be quite effective in a variety of application contexts, and validate its practicality through real-world attacks against traffic sign recognition, iris identification of volunteers, and facial recognition of public figures (politicians). Finally, we evaluate 4 potential defenses, and find that only one is effective in disrupting latent backdoors, but might incur a cost in classification accuracy as tradeoff.},
booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
pages = {2041–2055},
numpages = {15},
keywords = {artificial intelligence, machine learning, neural networks},
location = {London, United Kingdom},
series = {CCS '19}
}